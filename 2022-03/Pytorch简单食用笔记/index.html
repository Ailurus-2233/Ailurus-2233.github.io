

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/system/icon.jpg">
  <link rel="icon" href="/images/system/icon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Ailurus">
  <meta name="keywords" content="">
  
    <meta name="description" content="在学习深度学习的过程中，主要用到的工具为PyTorch，本文主要记录了一些基础的语法功能，以方便更进一步的深度网络的学习设计。">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch简单食用笔记">
<meta property="og:url" content="http://blog.ailurus2233.site/2022-03/Pytorch%E7%AE%80%E5%8D%95%E9%A3%9F%E7%94%A8%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Ailurusの客栈">
<meta property="og:description" content="在学习深度学习的过程中，主要用到的工具为PyTorch，本文主要记录了一些基础的语法功能，以方便更进一步的深度网络的学习设计。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.ailurus2233.site/page/2022-03/161550.png">
<meta property="article:published_time" content="2022-03-09T07:15:02.000Z">
<meta property="article:modified_time" content="2022-05-06T08:45:25.075Z">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="PyTorch">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://blog.ailurus2233.site/page/2022-03/161550.png">
  
  
  <title>PyTorch简单食用笔记 - Ailurusの客栈</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/atom-one-dark.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"blog.ailurus2233.site","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"|","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":"§"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
  <header style="height: 60vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Ailurus&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/images/system/background.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="PyTorch简单食用笔记">
              
            </span>

            
              <div class="mt-3">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-author" aria-hidden="true"></i>
      Ailurus
    </span>
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-03-09 15:15" pubdate>
        2022年3月9日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      6.5k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      54 分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">PyTorch简单食用笔记</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2022年5月6日 下午
                
              </p>
            
            <div class="markdown-body">
              <p>在学习深度学习的过程中，主要用到的工具为<code>PyTorch</code>，本文主要记录了一些基础的语法功能，以方便更进一步的深度网络的学习设计。</p>
<h1 id="张量">1.张量</h1>
<p>在pytorch中主要的计算单元，我的理解一个n阶张量就是一个n维数组，pytorch赋予了更多计算手段，以便于之后的高阶张量的计算。</p>
<p>在定义上，张量表示由一个数值组成的数组，这个数组可能有多个维度。具有一个轴的张量对应数学上的向量（vector）；具有两个轴的张量对应数学上的矩阵（matrix）；具有两个轴以上的张量没有特殊的数学名称。</p>
<h2 id="张量的创建">1.1张量的创建</h2>
<p>pytorch提供了多种多样的张量创建方式</p>
<ul>
<li><code>arange(n)</code> 函数类似python原来的
range(n)，创建一个张量，其元素是从0到n-1的整数，其形状为(1, n)</li>
<li><code>zeros((a1, a2, a3, ...))</code>
创建一个元素全为0的张量，其形状为(a1, a2, a3, ...)</li>
<li><code>ones((a1, a2, a3, ...))</code>
创建一个元素全为1的张量，其形状为(a1, a2, a3, ...)</li>
<li><code>rand((a1, a2, a3, ...))</code>
创建一个元素随机的张量，取值范围为[0, 1)，其形状为(a1, a2, a3, ...)</li>
<li><code>randn((a1, a2, a3, ...))</code>
创建一个元素满足均值为0，方差为1的正态分布张量，其形状为(a1, a2, a3,
...)</li>
<li><code>normal(mean=n, std=m, size=(a1, a2, a3, ...))</code>
创建一个元素满足均值为n，方差为m的正态分布张量，其形状为(a1, a2, a3,
...)
当<code>mean=0</code>，<code>std=1</code>时，等价与<code>randn()</code></li>
<li><code>tensor(arr)</code> 通过python的列表类型，创建一个张量</li>
</ul>
<h2 id="张量的操作">1.2 张量的操作</h2>
<p>pytorch中重构了运算符以及提供其他函数，使张量的运算更加方便</p>
<h3 id="基础运算符">1.2.1 基础运算符</h3>
<p>对于基础的运算符，张量间的运算方法如下</p>
<ul>
<li><code>+</code> 按元素求和</li>
<li><code>-</code> 按元素求差</li>
<li><code>*</code> 按元素求积</li>
<li><code>/</code> 按元素求商</li>
<li><code>**</code> 按元素求幂</li>
<li><code>%</code> 按元素求余</li>
<li><code>exp()</code> 按元素求e的指数</li>
<li><code>==</code> 按元素判断是否相等</li>
</ul>
<h3 id="函数操作">1.2.2 函数操作</h3>
<ul>
<li><code>shape</code> 函数返回张量的形状</li>
<li><code>size()</code> 函数返回张量的形状</li>
<li><code>reshape(a1, a2, a3, ...)</code>
函数返回一个新的张量，其形状为指定的形状，形状为(a1, a2, a3,
...)，是进一步的<code>view()</code></li>
<li><code>sum()</code> 对张量中的所有元素进行求和，会产生一个单元素张量
<ul>
<li><code>sum(axis = n)</code>
在张量中，按维度求和，会产生一个张量，阶数低于计算之前的张量</li>
</ul></li>
<li><code>numpy()</code> 将张量转化为NumPy张量</li>
<li><code>item()</code> 将张量转化为python的数字或者python原本的float(x)
int(x)也可以将张量转化为python的数字，但是仅限只有一个元素的时候</li>
<li><code>torch.cat((X, Y), dim = n)</code>
按照第n维度，将X和Y连结在一起，需要除了第n维度的其他形状相同</li>
<li><code>mean()</code> 对张量的所有元素求平均值
<ul>
<li><code>mean(axis = n)</code> 对张量的第n维元素求平均值</li>
</ul></li>
</ul>
<h3 id="广播机制">1.2.3 广播机制</h3>
<p>当两个张量的形状不同时，可以通过广播机制，将其中一个张量的形状转换成另一个张量的形状，能够广播的前提是参与运算的两个张量的形状在逻辑上可一通过复制扩充达到一致。
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">X = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>Y = torch.tensor([[<span class="hljs-number">4</span>], [<span class="hljs-number">5</span>]])<br>X + Y<br></code></pre></div></td></tr></table></figure> <figure class="highlight lua"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs lua">tensor(<span class="hljs-string">[[5, 6, 7],</span><br><span class="hljs-string">        [6, 7, 8]]</span>)<br></code></pre></div></td></tr></table></figure></p>
<h3 id="索引和切片">1.2.4 索引和切片</h3>
<p>torch的索引与python索引机制一致，这里记录一些常用操作</p>
<ul>
<li><code>X[-1]</code> 在第一维选择最后一个元素</li>
<li><code>X[1:3]</code> 在第一维选择下标[1, 3)的连续元素</li>
<li><code>X[1:3, 2:4]</code>
在第一维选择索引[1,3)的元素，在第二维选择索引为[2,4)的元素</li>
<li><code>X[1, 2, ...]</code> = n 修改张量里具体位置的值</li>
</ul>
<h3 id="内存节省方法">1.2.5 内存节省方法</h3>
<p>如果使用<code>Y=X+Y</code>这种运算方法的话，会导致额外的内存分配，通常使用<code>Y[:]=X+Y</code>或<code>Y+=X</code>来减少内存开销</p>
<h1 id="层与块">2. 层与块</h1>
<p>为了实现一些复杂的网络，我们引入了神经网络块的概念。块（block）可以描述单个层、由多个层组成的组件或整个模型本身。使用块进行抽象的一个好处是可以将一些块组合成更大的组件，这一过程通常是递归的，如下图所示
<img src="/page/2022-03/161550.png" srcset="/img/loading.gif" lazyload alt="层与块" /></p>
<p>从编程的⻆度来看，块由类（class）表示。它的任何子类都必须定义一个将其输入转换为输出的前向传播函数，并且必须存储任何必需的参数。注意，有些块不需要任何参数。最后，为了计算梯度，块必须具有反向传播函数。</p>
<h2 id="自定义块">2.1 自定义块</h2>
<h3 id="简单的自定义块">2.1.1 简单的自定义块</h3>
<p>每个块必须提供的基本功能：</p>
<ol type="1">
<li>将输入数据作为其前向传播函数的参数。</li>
<li>通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。</li>
<li>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。</li>
<li>存储和访问前向传播计算所需的参数。</li>
<li>根据需要初始化模型参数。</li>
</ol>
<p>在下面的代码片段中，我们从零开始编写一个块。它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一个10维输出层。注意，下面的MLP类继承了表示块的类。我们的实现<strong>只</strong>需要提供我们自己的构造函数（Python中的__init__函数）和前向传播函数。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.hidden = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">256</span>)<br>        self.out = nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-keyword">return</span> self.out(F.relu(self.hidden(X)))<br></code></pre></div></td></tr></table></figure>
<p>新建网络和执行<code>forward()</code>方法 <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">net = MLP()<br>net(X)<br></code></pre></div></td></tr></table></figure></p>
<h3 id="在向前传播中执行其他计算代码">2.1.2
在向前传播中执行其他计算代码</h3>
<p>在对于向前传播中，pytorch可以做很多操作，来满足各种各样的架构的复杂运算，如下所示代码，它的向前传播进行四步计算：1.全连接层；2.常数参数乘积计算，全元素+1后计算relu；3.全连接层；4.第一范数大于1，全元素/2；5.返回全元素和。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>    X = self.linear(X)<br>    X = self.relu(torch.mm(self.con_weight, X) + <span class="hljs-number">1</span>)<br>    X = self.linear(X)<br>    <span class="hljs-keyword">while</span> X.<span class="hljs-built_in">abs</span>().<span class="hljs-built_in">sum</span>() &gt; <span class="hljs-number">1</span>:<br>        X /= <span class="hljs-number">2</span><br>    <span class="hljs-keyword">return</span> X.<span class="hljs-built_in">sum</span>()<br></code></pre></div></td></tr></table></figure>
<p>那么我们可以随心所欲的在<code>forward</code>中实现我们复杂的数学计算，（只要数学公式是正确的）</p>
<h3 id="块与块的嵌套">2.1.3 块与块的嵌套</h3>
<p>我们可以使用<code>Sequential()</code>来简单连接不同的块，当然，使用一个大的块来进行更复杂网络设计也是可行的
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">chimera = nn.Sequential(NestMLP(), nn.Linear(<span class="hljs-number">16</span>,<span class="hljs-number">20</span>), FixedHiddenMLP())<br></code></pre></div></td></tr></table></figure></p>
<h3 id="不带参数的自定义层">2.1.4 不带参数的自定义层</h3>
<p>我们如果想要减去均值，那么可以有如下定义的层，它是一个不包含任何参数的层
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CenteredLayer</span>(nn.Module):<br>	<span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    	<span class="hljs-built_in">super</span>().__init__()<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>    	<span class="hljs-keyword">return</span> X - X.mean()<br></code></pre></div></td></tr></table></figure></p>
<h3 id="带参数的自定义层">2.1.5 带参数的自定义层</h3>
<p>同样，参数我们也可以自己来定义，定义方式如下，我们也可以通过forward来定义向前传播的计算方法
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyLinear</span>(nn.Module):<br>	<span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_units, units</span>):<br>    	<span class="hljs-built_in">super</span>().__init__()<br>        self.weight = nn.Parameter(torch.randn(in_units, units))<br>        self.bias = nn.Parameter(torch.randn(units,))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>    	linear = torch.matmul(X,self.weight.data) + self.bias.data<br>        <span class="hljs-keyword">return</span> F.relu(linear)<br></code></pre></div></td></tr></table></figure></p>
<h2 id="块的参数管理">2.2 块的参数管理</h2>
<p>对于块的参数实际上是一个个张量，我只要访问到张量，通过张量的访问方式就能访问到参数。</p>
<h3 id="参数访问">2.2.1 参数访问</h3>
<p>当通过<code>Sequential</code>类定义模型时，我们可以通过索引来访问模型的任意层。这就像模型是一个列表一样，每层的参数都在其属性中。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].state_dict())<br></code></pre></div></td></tr></table></figure>
<p>注意，每个参数都表示为参数类的一个实例。要对参数执行任何操作，首先我们需要访问底层的数值。有几种方法可以做到这一点。有些比较简单，而另一些则比较通用。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(net[<span class="hljs-number">2</span>].bias))<br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].bias)<br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].bias.data)<br></code></pre></div></td></tr></table></figure>
<p>参数是复合的对象，包含值、梯度和额外信息。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">net[<span class="hljs-number">2</span>].weight.grad==<span class="hljs-literal">None</span><br></code></pre></div></td></tr></table></figure>
<p>通过for-each可以方便的遍历所有参数 <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(*[(name, param.shape)<span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> net[<span class="hljs-number">0</span>].named_parameters()])<br><span class="hljs-built_in">print</span>(*[(name, param.shape)<span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> net.named_parameters()])<br></code></pre></div></td></tr></table></figure></p>
<p>输出： <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">(<span class="hljs-string">&#x27;weight&#x27;</span>, torch.Size([<span class="hljs-number">8</span>,<span class="hljs-number">4</span>])) (<span class="hljs-string">&#x27;bias&#x27;</span>, torch.Size([<span class="hljs-number">8</span>]))<br>(<span class="hljs-string">&#x27;0.weight&#x27;</span>, torch.Size([<span class="hljs-number">8</span>,<span class="hljs-number">4</span>])) (<span class="hljs-string">&#x27;0.bias&#x27;</span>, torch.Size([<span class="hljs-number">8</span>])) (<span class="hljs-string">&#x27;2.weight&#x27;</span>, torch.,Size([<span class="hljs-number">1</span>,<span class="hljs-number">8</span>])) (<span class="hljs-string">&#x27;2.bias&#x27;</span>, torch.Size([<span class="hljs-number">1</span>]))<br></code></pre></div></td></tr></table></figure></p>
<p>根据结果，我们不难得到一种新的访问方式 <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">net.state_dict()[<span class="hljs-string">&#x27;2.bias&#x27;</span>].data<br></code></pre></div></td></tr></table></figure></p>
<p>对于嵌套块的，可以像嵌套列表索引一样访问它们</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">rgnet[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>][<span class="hljs-number">0</span>].bias.data<br></code></pre></div></td></tr></table></figure>
<h3 id="参数初始化">2.2.2 参数初始化</h3>
<p>通过<code>net.apply(init_func)</code>的方法来初始化参数，如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_normal</span>(<span class="hljs-params">m</span>):<br>  	<span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br> 		nn.init.normal_(m.weight, mean=<span class="hljs-number">0</span>, std=<span class="hljs-number">0.01</span>)<br>        nn.init.zeros_(m.bias)<br>net.apply(init_normal)<br></code></pre></div></td></tr></table></figure>
<p>其中<code>.normal_()</code>与<code>.zero_()</code>与之前的创建张量的函数有着相同的作用。常用的内置初始化函数有</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">nn.init.normal_(m.weight, mean=<span class="hljs-number">0</span>, std=<span class="hljs-number">0.01</span>)<br>nn.init.uniform_(m.weight, -<span class="hljs-number">10</span>,<span class="hljs-number">10</span>)<br>nn.init.constant_(m.weight,<span class="hljs-number">1</span>)<br>nn.init.xavier_uniform_(m.weight)<br>nn.init.zeros_(m.bias)<br></code></pre></div></td></tr></table></figure>
<p>当然我们随时都可以直接访问每一层的每一个参数，那么我们能够在初始化函数中，写的一些比较复杂的初始化操作。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">net[<span class="hljs-number">0</span>].weight.data[:]+=<span class="hljs-number">1</span><br>net[<span class="hljs-number">0</span>].weight.data[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]=<span class="hljs-number">42</span><br>net[<span class="hljs-number">0</span>].weight.data[<span class="hljs-number">0</span>]<br></code></pre></div></td></tr></table></figure>
<h1 id="文件读写">3. 文件读写</h1>
<p>有时我们希望保存训练的模型，以备将来在各种环境中使用，pytorch也提供了一系列方法用来保存数据。</p>
<h2 id="加载与保存张量">3.1 加载与保存张量</h2>
<p>对于单个张量，我们可以直接调用load和save函数分别读写它们。
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">x = torch.arange(<span class="hljs-number">4</span>)<br>torch.save(x,<span class="hljs-string">&#x27;x-file&#x27;</span>)<br>x2 = torch.load(<span class="hljs-string">&#x27;x-file&#x27;</span>)<br></code></pre></div></td></tr></table></figure></p>
<p>存储词典，可以用来存储一些权重之类的信息 <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">mydict = &#123;<span class="hljs-string">&#x27;x&#x27;</span>: x,<span class="hljs-string">&#x27;y&#x27;</span>: y&#125;<br>torch.save(mydict,<span class="hljs-string">&#x27;mydict&#x27;</span>)<br>mydict2 = torch.load(<span class="hljs-string">&#x27;mydict&#x27;</span>)<br></code></pre></div></td></tr></table></figure></p>
<h2 id="加载与保存模型参数">3.2 加载与保存模型参数</h2>
<p>保存单个权重向量（或其他张量）确实有用，但是如果我们想保存整个模型，并在以后加载它们，单独保存每个向量则会变得很麻烦。毕竟，我们可能有数百个参数散布在各处。因此，pytorch提供了内置函数来保存和加载整个网络。需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">net = MLP()<br>torch.save(net.state_dict(),<span class="hljs-string">&#x27;mlp.params&#x27;</span>)<br><br>clone = MLP()<br>clone.load_state_dict(torch.load(<span class="hljs-string">&#x27;mlp.params&#x27;</span>))<br></code></pre></div></td></tr></table></figure>
<h1 id="gpu">4. GPU</h1>
<h2 id="获取计算设备">4.1 获取计算设备</h2>
<p>在pytorch中，CPU和GPU可以用<code>torch.device('cpu')</code>和<code>torch.device('cuda')</code>表示。应该注意的是，cpu设备意味着所有物理CPU和内存，这意味着pytorch的计算将尝试使用所有CPU核心。然而，gpu设备只代表一个卡和相应的显存。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>), torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span>), torch.device(<span class="hljs-string">&#x27;cuda:1&#x27;</span>)<br></code></pre></div></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">(device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cpu&#x27;</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">1</span>))<br></code></pre></div></td></tr></table></figure>
<p>我们还可一获取GPU设备的数量 <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">torch.cuda.device_count()<br></code></pre></div></td></tr></table></figure></p>
<p>我们可以定义这样的函数来快速获取设备信息 <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">deftry_gpu(i = <span class="hljs-number">0</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    如果存在，则返回gpu(i)，否则返回cpu()</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> torch.cuda.device_count() &gt;= i+<span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> torch.device(<span class="hljs-string">f&#x27;cuda:<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">return</span> torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">try_all_gpus</span>():<span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    返回所有可用的GPU，如果没有GPU，则返回[cpu(),]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    devices = [torch.device(<span class="hljs-string">f&#x27;cuda:<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(torch.cuda.device_count())]<br>    <span class="hljs-keyword">return</span> devices <span class="hljs-keyword">if</span> devices <span class="hljs-keyword">else</span> [torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)]<br></code></pre></div></td></tr></table></figure></p>
<h2 id="计算设备的选择">4.2 计算设备的选择</h2>
<p>对于张量，如果想使用GPU的话，在创建时可以添加参数<code>device=cuda:0</code>，那么将会在第一块GPU上创建这个张量</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">X = torch.ones(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>, device=try_gpu()<br></code></pre></div></td></tr></table></figure>
<p>也可以通过复制的手段，将向量添加到另一块GPU上</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">Z = X.cuda(<span class="hljs-number">1</span>)<br></code></pre></div></td></tr></table></figure>
<p>对于模型参数，可以通过<code>model.to(device='cuda:0')</code>来将整个参数放到GPU上</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">net = nn.Sequential(nn.Linear(<span class="hljs-number">3</span>,<span class="hljs-number">1</span>))<br>net = net.to(device=try_gpu())<br></code></pre></div></td></tr></table></figure>
<h3 id="其他注意事项">4.3 其他注意事项</h3>
<p>深度学习框架要求计算的所有输入数据都在同一设备上，无论是CPU还是GPU。</p>
<p>不经意地移动数据可能会显著降低性能。一个典型的错误如下：计算GPU上每个小批量的损失，并在命令行中将其报告给用戶（或将其记录在NumPyndarray中）时，将触发全局解释器锁，从而使所有GPU阻塞。最好是为GPU内部的日志分配内存，并且只移动较大的日志。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Python/">Python</a>
                    
                      <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                      <a class="hover-with-bg" href="/tags/PyTorch/">PyTorch</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022-05/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Go语言学习笔记-变量、常量、数据类型</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022-03/Hello%20Hexo/">
                        <span class="hidden-mobile">Hello Hexo</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        豫ICP备2022006334号-1
      </a>
    </span>
    
      
        <span>
          <a
            href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=41900102411004"
            rel="nofollow noopener"
            class="beian-police"
            target="_blank"
          >
            
              <span style="visibility: hidden; width: 0">|</span>
              <img src="/images/system/beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"/>
            
            <span>豫公网安备 41900102411004号</span>
          </a>
        </span>
      
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>

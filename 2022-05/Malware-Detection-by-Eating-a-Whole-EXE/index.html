

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/system/icon.jpg">
  <link rel="icon" href="/images/system/icon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Ailurus">
  <meta name="keywords" content="">
  
    <meta name="description" content="在这项工作中，我们将原始字节序列中的恶意软件检测作为一个富有成果的研究领域介绍给更大的机器学习社区。为此类问题构建神经网络提出了许多有趣的挑战，这些挑战在图像处理或 NLP 等任务中并未出现。特别是，我们注意到从原始字节中检测存在超过 200 万个时间步长的序列问题，以及批量归一化似乎阻碍学习过程的问题。我们提出了我们的初步工作，以建立一个解决方案来解决这个问题，它具有线性复杂度依赖于序列长度，并">
<meta property="og:type" content="article">
<meta property="og:title" content="Malware Detection by Eating a Whole EXE 文章翻译">
<meta property="og:url" content="http://blog.ailurus2233.site/2022-05/Malware-Detection-by-Eating-a-Whole-EXE/index.html">
<meta property="og:site_name" content="Ailurusの客栈">
<meta property="og:description" content="在这项工作中，我们将原始字节序列中的恶意软件检测作为一个富有成果的研究领域介绍给更大的机器学习社区。为此类问题构建神经网络提出了许多有趣的挑战，这些挑战在图像处理或 NLP 等任务中并未出现。特别是，我们注意到从原始字节中检测存在超过 200 万个时间步长的序列问题，以及批量归一化似乎阻碍学习过程的问题。我们提出了我们的初步工作，以建立一个解决方案来解决这个问题，它具有线性复杂度依赖于序列长度，并">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.ailurus2233.site/page/2022-05/MalConv.png">
<meta property="article:published_time" content="2022-05-17T01:15:57.000Z">
<meta property="article:modified_time" content="2022-05-23T09:40:43.267Z">
<meta property="article:tag" content="论文翻译">
<meta property="article:tag" content="恶意代码检测">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://blog.ailurus2233.site/page/2022-05/MalConv.png">
  
  
  <title>Malware Detection by Eating a Whole EXE 文章翻译 - Ailurusの客栈</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/atom-one-dark.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"blog.ailurus2233.site","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"|","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":"§"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
  <header style="height: 60vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Ailurus&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/images/system/background.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Malware Detection by Eating a Whole EXE 文章翻译">
              
            </span>

            
              <div class="mt-3">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-author" aria-hidden="true"></i>
      Ailurus
    </span>
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-05-17 09:15" pubdate>
        2022年5月17日 上午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      12k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      101 分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Malware Detection by Eating a Whole EXE 文章翻译</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2022年5月23日 下午
                
              </p>
            
            <div class="markdown-body">
              <h1 id="概述">概述</h1>
<p>恶意软件的检测是网络安全中的重要问题，尤其是随着社会越来越多地依赖于计算系统。恶意软件的单一事件已经会导致数百万美元的损失
(Anderson等人2013)。防病毒产品提供了一些针对恶意软件的保护，但对这个问题越来越无效。当前的反病毒技术使用基于签名的方法，其中签名是一组手动制定的规则，旨在识别恶意软件的一小部分。这些签名通常是特定的，即使使用相同的功能，通常也无法识别新的恶意软件。这种方法是不够的，因为大多数环境将拥有以前从未见过的独特二进制文件（Li
et al.
2017），并且每天都会发现数百万个新的恶意软件样本。多年来，反病毒提供商和行业专家已经认识到签名的局限性
(Spafford
2014)。开发推广到新恶意软件的技术的需求将使恶意软件检测的任务似乎非常适合机器学习，尽管存在重大挑战。</p>
<p>要构建恶意软件检测系统，我们必须首先确定要使用的特征集。一种直观的选择是使用通过监视程序执行获得的功能
(称为apis，执行的指令，访问的ip地址等)。这被称为动态分析。在直观地吸引人的同时，动态分析在实践中存在许多问题。为了进行动态分析，恶意软件必须在特殊仪器环境中运行，例如定制的虚拟机
(VM)，这会带来很高的计算要求。此外，在某些情况下，恶意软件有可能在对其进行分析时进行检测。当恶意软件检测到对其进行分析的尝试时，恶意软件可以改变其行为，从而避免被发现（Raffetseder、Kruegel
和 Kirda 2007；Garfinkel 等人 2007；Carpenter、Liston 和 Skoudis
2007）。即使当恶意软件不表现出这种行为时，分析环境也可能不反映恶意软件的目标环境，从而在所收集的训练数据与现实环境之间产生差异
(Rossow等人2012)。虽然动态分析组件可能是长期解决方案的重要组件，但由于其增加的复杂性，我们此时会避免使用它。</p>
<p>相反，我们采用静态分析方法，我们从二进制程序中查看无需运行即可获得的信息。特别是，我们查看文件本身的原始字节，并构建一个神经网络来确定恶意。神经网络在从图像（Szegedy
et al.2015）、信号（Graves、Mohamed和Hinton 2013）和文本（Zhang和LeCun
2015）问题的原始输入中学习特征方面表现出色。在恶意软件领域复制这种成功可能有助于简化用于检测恶意软件的工具并提高准确性。由于恶意软件可能会利用错误并忽略格式规范，因此解析恶意文件并使用需要域知识的功能可能需要大量而非平凡的工作。由于恶意软件是由真正的实时对手编写的，因此此类代码还需要维护和改进以适应恶意软件作者不断变化的行为。</p>
<p>由于我们希望从原始字节输入中学习一个系统，从中构建更高级别的表示，我们选择使用基于神经网络的方法。但是，该领域存在许多其他任务中没有遇到的挑战和差异。从机器学习的角度来看，这些挑战使恶意软件检测的研究本质上变得有趣且相关，而不仅仅是将这些技术引入新的领域。对于Microsoft
Windows可移植可执行（PE）恶意软件，这些挑战包括但不限于：</p>
<ol type="1">
<li>恶意软件中的字节可以具有多种形式的信息。这意味着任何特定字节的含义是上下文相关的，并且可以是编码人类可读文本
(例如，来自导入表的函数名称) 、二进制代码、诸如图像的任意对象
(来自二进制的资源/数据部分) 等等。</li>
<li>二进制文件的内容表现出多种类型的空间相关性。函数中的代码指令在空间上是内在相关的，但是这种相关性与函数调用和跳转命令具有不连续性。此外，如果正确地校正了地址，则可以任意地重新排列功能级别的内容。</li>
<li>将每个字节视为序列中的一个单元，我们正在处理200万时间步长顺序的序列分类问题。据我们所知，这远远超过了以前任何基于神经网络的序列分类器的输入长度。</li>
<li>随着时间的推移，我们的问题有多个层次的概念漂移。开发人员使用的应用程序、构建工具和库自然会得到更新，替代品也会受到青睐。仅此一项就会导致概念漂移。但是恶意软件是由现实生活中的对手编写的，并且经常被故意调整以避免被发现。</li>
</ol>
<p>我们在这项工作中的贡献是开发了第一个网络体系结构，该体系结构可以成功处理超过200万个步骤的原始字节序列。其他人已经尝试了该任务，但未能超越更简单的基线或成功处理整个文件
(Anderson
2017)，部分原因是为信号和图像处理开发的技术并不总是转移到该新域。我们确定了让网络从原始字节中检测恶意软件所涉及的挑战，以及成功训练此类模型的初始方法。我们表明，与以前的无领域知识恶意软件检测方法相比，该模型学习了更广泛的信息类型。我们的工作还突出了批量规范化的失败案例，这最初导致我们的模型无法学习。</p>
<h1 id="相关工作">相关工作</h1>
<p>过去的工作有两个主要主题：神经网络在更长序列中的应用，以及神经网络在恶意软件检测中的应用。循环神经网络
(rnn)
的使用在历史上在涉及序列的任何工作中都很普遍，但是原始字节的处理远远超过了先前工作中尝试的数量级。对于恶意软件检测，所有这些以前的应用程序都使用大量的领域知识进行特征提取。相比之下，我们的目标是尽量减少此类领域知识的使用，并探索在不指定任何此类信息的情况下可以解决多少问题。</p>
<h2 id="适用于长序列的神经网络">适用于长序列的神经网络</h2>
<p>在这项工作中探索的层序分类规模方面，几乎没有做过什么工作。就纯序列长度而言，最接近的是
WaveNet (Oord et al.
2016)。WaveNet试图通过忽略先前的特征工程，而不是使用音频的原始字节作为输入特征和目标，来提高生成音频的最新水平。这导致音频每秒16,000时间步长的序列问题。通过使用扩张的卷积
(Yu和Koltun 2016) 并通过训练非常深的体系结构获得了此任务的广泛接受场
(4,800步骤)。最终，与我们的恶意软件检测问题相比，他们的工作在序列长度上仍然是两个数量级。</p>
<p>使用扩张卷积来处理序列长度已经成为一种普遍趋势，例如在用于机器翻译的ByteNet模型中
(Kalchbrenner等人2016)。虽然翻译会产生相对较长的序列，但它们的序列长度比
WaveNet
的音频生成要小。虽然我们在这项工作中确实探索了扩张卷积，但我们没有发现它们在我们的问题上比标准卷积表现得更好或更差。我们怀疑这是由于二进制文件中局部性的不同性质，对于空间上一致的域
(例如图像分类)，膨胀的 “孔”
中的值更容易假设或插值，但对于二进制内容却没有明显插值。</p>
<p>我们注意到使用长序列时的另一种趋势:
使用以不同频率运行的RNN。Mehri等人 (2017)
使用这样的体系结构进行音频分类，但是利用任务的生成性来训练仅512时间步长的子序列。其他使用在多个频率上运行的
RNN 的工作类似地处理了不超过数千个时间步长的序列（Koutnik 等人
2014；Neil、Pfeiffer 和 Liu 2016）。</p>
<p>除了在处理我们面临的异常长的序列时遇到困难之外，我们还必须应对缺乏信息流的问题。当对二进制进行良性/恶意分类时，我们仅获得一个错误信号，该信号必须用于通知有关所有200万时间步骤的决策。相比之下，神经翻译模型和自回归模型（如WaveNet）试图预测的不是整体分类，而是下一个单词或字节。这为他们在每个时间步提供了频繁的标签信息，从而在输入大小和传播错误的标签之间形成了接近1:1的映射。这种频繁的梯度信息不适用于我们的问题，甚至在考虑序列长度之前就增加了学习挑战。</p>
<h2 id="用于恶意软件检测的神经网络">用于恶意软件检测的神经网络</h2>
<p>到目前为止，在将神经网络应用于恶意软件检测方面几乎没有什么工作，而且我们知道目前没有任何工作试图从整个二进制文件的原始字节中做到这一点。最近已经证明，<strong>当从每个文件
(Raff，Sylvester和Nicholas 2017)
的PE头仅300字节训练时，全连接和循环网络能够学习恶意软件识别问题</strong>。基于获得的积极结果，当前的工作通过在整个数百万字节长的可执行文件上训练网络来扩展这些结果，并遇到了广泛的潜在字节内容。</p>
<p>Saxe和Berlin (2015)
的工作在特征级别上与我们的工作最接近，因为它使用了特征的字节熵值直方图。除了可以通过静态分析获得的ASCII字符串长度，PE导入和其他元数据的直方图之外。这种方法从整个文件中产生一些小级别的信息，但在这个过程中丢弃了有关二进制文件实际内容的大部分信息，因为它创建了一个固定长度的特征向量，用作网络的输入。</p>
<p>在将深度学习应用于恶意软件检测方面的最新工作使用了通过动态分析提取的功能，其中二进制文件在虚拟化环境中运行以获取有关其执行的信息。Kolosnjaji
等人。（2016）解决了恶意软件家族分类的相关问题（即，特定恶意文件属于哪个家族？）使用卷积的组合，然后使用
LSTM 来处理在动态分析下生成的恶意软件文件的 API
调用序列。这是在选择只跟踪60个内核API调用之后。</p>
<p>Huang 和 Stokes (2016) 将 API
调用手动特征工程为114个更高级别的概念，并将这些API事件与原始函数调用的输入参数以及三元组相结合。他们不仅仅是预测恶意，而是使用相同的模型
(即两个任务之间共享的权重)
进行恶意软件检测和家族分类。这种方法提高了模型在两个任务上的性能，并且将与我们在这项工作中的设计兼容。</p>
<p>这些先前在恶意软件检测中的工作倾向于使用重要的手动功能工程，这需要重要的
(如果不是罕见的话)
领域专业知识水平。那些使用动态分析的人通常依靠复杂的非公共仿真环境来减轻动态分析的挑战，这大大增加了重现工作的工作量。我们提出的方法消除了这种特定于领域知识的代码和特征处理，减少了专门代码的数量，减少了复制和扩展的障碍。</p>
<p>我们注意到以前在恶意软件检测方面的许多工作的一个不幸方面，包括我们自己的一些工作，即由于各种原因，使用了公众无法获得的数据。正如我们将在第3章中讨论的那样，公众容易获得的数据通常质量不足以在实践中使用。这也意味着我们无法有意义地比较各个作品的准确性数字，因为不同的数据集与不同的标签程序一起使用。</p>
<h1 id="训练数据集">训练数据集</h1>
<p>对于这项工作，我们使用与<strong>Raff等人 (2016)
相同的训练和测试数据</strong>。具体来说，我们使用B组培训数据和A&amp;B组测试数据。B组数据由反病毒行业合作伙伴提供，其中良性程序和恶意程序都代表真实计算机上看到的文件。B组训练集由在良性和恶意类之间平均分配的400,000文件组成。测试集有77,349文件，其中40,000是恶意的，其余是良性的。</p>
<p>A组数据的收集方式与恶意软件识别文献（Schultz et al.2001；Kolter and
Maloof
2006）中的大多数工作相同，该文献可供公众使用。良性数据（或“goodware”）来自微软Windows的干净安装，以及一些常用安装的应用程序（如Firefox、Flash等），恶意软件来自VirusShare语料库（Roberts
2011）。A组测试集包含43967个恶意测试文件和21854个良性测试文件。</p>
<p>研究发现，对A组数据的培训会导致严重的过度拟合（Raff等人，2016年），学习识别“来自微软”而不是“良性”，这不会推广到新数据。也就是说，在a组上训练的模型不会推广到B组，但是在B组上训练的模型会推广到A组。因此，我们仅使用B组训练数据进行实验，并在两组上进行测试。以这种方式进行测试使我们能够更好地量化泛化能力，因为数据来自不同的来源。这样可以最大程度地减少共享偏差，并为我们提供了预期准确性的潜在上限和下限。</p>
<p>我们使用两组的测试集，因为这使我们能够更好地判断模型的泛化能力。B
组的测试性能很重要，因为它应该代表野外数据，但由于 B
组数据的收集方式，可能存在共同的偏见。对以不同方式收集的 A
组数据进行测试是一种更强的泛化测试，因为该数据与 B
组的常见偏差较少。因此，我们认为A组的测试性能比B组更有趣。我们还希望我们的模型在两个测试集上具有相似的性能，这将表明所学习的功能非常有用。</p>
<p>此外，与作者和原始公司接触，我们获得了更大的2,011,786二进制文件的培训语料库，1,000,020良性和1,011,766恶意。我们使用这个更大的数据集来表明，随着训练数据的增加，我们新的MalConv体系结构不断改进，而字节n-gram方法在性能方面似乎已经趋于稳定。</p>
<h1 id="模型架构">模型架构</h1>
<p>在设计我们的模型时，需要三个特性：1) 能够很好地随序列长度扩展，2)
在检查整个文件时考虑本地和全局上下文的能力，以及 3)
帮助分析标记的恶意软件的解释能力。这个模型的框图，我们称之为 MalConv，在
1 中给出，更详细的图表在补充材料中。</p>
<p>可执行文件的大量位置变化影响了我们在可执行文件中的位置选择。在较高的级别上，PE二进制文件的内容几乎可以任意顺序重新排列。唯一的固定常量是
MS-DOS 标头，它以指向 PE-Header
开头的指针结束。然后，PE标头可以位于任何位置，并且它的一部分可以位于整个文件中。PE头本身包含指向二进制文件所有其他内容（代码、资源等）的指针。这允许在不改变含义的情况下对字节内容进行宏重组。类似地，即使在二进制代码的代码部分中，只要正确调整代码中使用的集合的地址，函数的定义也可以重新排序。这是可能发生的另一个空间重组水平。这种宏观级别的重新排序代表了二进制文件中许多类型的空间属性之一，但我们认为它是最重要的解决方案。功能级别的空间不连续性仍然很困难，但对于模型学习来说并非不可克服。可能会遗漏大范围的相关性；我们希望在未来的工作中获取这些信息。</p>
<p>为了最好地捕获这种高级位置不变性，我们选择使用卷积网络体系结构。在进入全连接层之前，将卷积激活与max-pooling相结合，使我们的模型能够产生其激活，而不管检测到的特征的位置如何。而不是对原始字节值执行卷积
(即，使用从0到255的字节值的缩放版本)，我们使用嵌入层将每个字节映射到固定长度
(而不是学习)
的特征向量。我们避免使用原始字节值，因为它暗示了一种解释，即某些字节值本质上比其他字节值
“更接近”
彼此，我们先验地知道这是假的，因为字节值的含义取决于上下文。与卷积一起训练嵌入甚至可以让我们的浅层网络激活更广泛的输入模式。这也使它在面​​对字节值的微小变化时具有一定程度的鲁棒性。使用字节n-grams的先前工作缺乏这种质量，因为它们依赖于精确的字节匹配
(Kolter和Maloof 2006; Raff等人2016)。</p>
<p>我们注意到，在为如此长的输入序列开发神经网络体系结构时，必须做出许多困难的设计选择。实践中的一个主要限制是第一个卷积层中的GPU内存消耗。无论卷积大小如何，在第一次卷积后存储激活以进行正向传播很容易在反向传播期间导致内存不足错误。我们选择使用大卷积滤波器和步幅来控制这些早期层中激活所使用的记忆。</p>
<p>试图在如此长的序列上构建深度架构需要我们的数据层之间的积极共享，这导致了不平衡的内存使用。这使得Tensorflow等框架中的模型并行性难以实现。相反，我们选择创建一个浅层架构，该架构具有500字节的大过滤器宽度和积极的500步伐。这使我们能够使用PyTorch
(Paszke，Gross和Chintala 2016)
以数据并行的方式更好地平衡计算工作量。我们的卷积结构使用Dauphin等人
(2016) 之后的门控卷积方法，并带有128滤波器。</p>
<p><strong>Regularization</strong>
跨测试架构的一致结果是过度拟合的倾向。这并不奇怪，因为我们的输入特征空间很大（200万个时间步），我们必须从中学习基于单个损失的良性/恶意分类。特别是，我们注意到从B组训练数据到B组测试数据以及B组训练数据到A组测试数据的推广困难。在开发过程中，我们发现
DeCov 正则化 (Cogswell et al. 2016)
最有帮助，它会惩罚倒数第二层隐藏状态激活之间的相关性。</p>
<p>我们工作中的一个重大挑战是发现批处理规范化阻止了我们的模型学习这个问题。批量归一化已成为深度学习文献中的一个常见工具，既能更快地收敛，又能产生正则化效果，通常可提高泛化（Ioffe和Szegedy
2015）。这使得我们数据上的批量标准化失败成为一个有趣且独特的结果，我们将在
5.3 中讨论。</p>
<p><img src="/page/2022-05/MalConv.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="关于失败的架构">关于失败的架构</h2>
<p>针对这个问题测试了大量的替代架构设计，包括多达 13
层卷积、使用各种（双向）RNN
和不同的注意力模型。提MalConv体系结构在许多候选中表现最好。我们在这里回顾了其他高级替代架构策略，它们未能超越我们更简单的MalConv的原因，以及它们如何与最终设计相关联。其他详细信息可在附录中找到。</p>
<p>由于上述用于反向传播的大量内存使用，因此可以以减少批处理大小为代价添加更多的层。我们使用多达
13
层卷积对此进行了测试，发现性能只会下降。其中许多实验尝试了较小的卷积场，因此神经元的总感受野在
500 到 1000
个时间步长的范围内。这些方法的问题是，除了将训练时间增加到无法预估的程度之外，由于标准方法是在每轮池化之后将卷积滤波器的数量增加一倍以保持每层的状态量大致相等，因此这是不可能的。200万步后的卷积状态太大，无法合理计算。因此，需要快速压缩每层的状态大小，但这最终会抑制学习。在我们的方法中，我们在一次卷积中将大量信息移动到宽的滤波器宽度中，允许我们在不增加内存使用的情况下练习和保留信息。</p>
<p>另一种设计选择是在一个大卷积中同时处理整个文件。一个吸引人的想法是将输入分解为500到10,000字节的块，并独立处理每个块，因为这将大大降低训练要求。我们测试了这种方法，虽然它达到了95%
的合理精度，但通常无法推广到65-80%
范围内的新数据获取测试精度。这是因为给定二进制文件的大部分内容可能对恶意决策完全没有意义，在随机数据块上进行训练并假设恶意标签会鼓励模型过度拟合训练数据，并记住内容以产生正确的决策。我们的
MalConv
模型可以访问整个文件，这使模型能够检测到少数信息特征，而不管位置如何。这对于避免上述各种过度拟合是必要的，并且对于在通常良性程序已将恶意软件注入其中的情况下工作是客观必要的。在这种常见情况下，大部分文件应该正确地指示一个良性程序，而只有一小部分内容是恶意的。</p>
<p>信息稀疏性问题也是我们选择使用时间最大池而不是平均池的一个因素。除了提供更好的可解释性外，maxpooling还提供了相对于平均池的卓越性能。后者强制要求信息特征应该广泛出现在基础文件中。但是许多特征在文件中只会出现一次，因此当与平均池结合使用时，该特征在二进制文件的一个区域中的高响应将被文件中产生低激活的其余大部分部分冲走。Max
pooling避免了这个问题，同时仍然允许我们解决可变长度问题。</p>
<p>虽然RNNs是任何序列相关任务的通用工具，但我们发现它们在卷积后应用时降低了测试精度，方法是将每次卷积后的输出分解为多个固定大小的块
(最后一个块包含填充)。虽然要采取直观的步骤，但这也将先验引入到模型中，即来自卷积的数据必须在固定频率下定期产生相同的激活模式。这是因为
RNN 的输入将 CNN
的时间输出重新整形为非时间矩阵乘法，因此要求时间信息出现在一致的位置，其周期等于确定的任何块大小。这是因为
RNN 的输入将 CNN
的时间输出重新整形为非时间矩阵乘法，因此要求时间信息出现在一致的位置，其周期等于确定的任何块大小。</p>
<h1 id="结果">结果</h1>
<p>现在，我们介绍神经网络模型的结果。为了评估其性能和有效性，我们将研究5.1中准确性的标准度量，研究5.2中学习的特征的泛化能力，并解决5.3中的批标准化问题。我们还将花一点时间注意构建此模型所需的计算约束。为了使模型及时收敛，我们必须使用相对较大的批次大小，每批次256个样品。由于该体系结构的极端内存使用，因此无法在单个GPU上执行此操作。我们能够在400k组B组上使用DGX-1的8个gpu上的数据并行性训练该模型，每个时期16.75小时，持续10个时期，并使用所有可用的GPUmemory。在同一系统上对较大的200万进行培训需要一个月。</p>
<h2 id="恶意软件分类">恶意软件分类</h2>
<p>在评估我们模型的预测性能时，我们使用平衡准确度 (Brodersen et al.
2010)（即准确度加权，以便良性和恶意样本均匀计数）和 AUC (Bradley
1997)。我们使用平衡的准确性，以便我们在A组和B组测试集中的结果可直接比较，因为它们具有不同比例的良性和恶意样本。由于需要执行恶意软件分类，AUC是一个特别相关的指标，其中基于优先级结构
(Jang，Brumley和Venkataraman 2011)
创建了要查看的二进制文件队列。最好让最恶意的文件在队列中排名最高，以便尽早识别和隔离它们。分析师的时间很昂贵，并且表征单个二进制文件可能需要超过10个小时
(Mohaisen和Alrawi
2013)。高AUC得分对应于大多数恶意软件在最好软件之上的成功排名，使其成为直接适用的评估指标。我们特别注意A组测试集的准确性，因为它与B组训练集的相关性最少。因此，组A上的精度性能是泛化性能的更强度量。在这种情况下，我们还对哪些模型在组A和B之间的性能差异最小感兴趣，这表明模型并未过度适合源分布。</p>
<p>尽管手头的任务很困难，但我们发现我们的网络往往会在训练语料库仅经过三个时期后迅速收敛。这在某些方面是有益的，因为每个时期的训练时间很重要。我们相信这种快速融合可能部分归因于我们架构的小尺寸，它具有
(仅!)134,632可训练参数。精度结果如表1所示。我们的模型在经过正规化和非正规化训练时都能够实现较高的AUC，这表明它们对于恶意软件分类非常有用，有助于对工作队列进行排序。</p>
<p>查看结果，我们可以看到我们的 MalConv
模型在指标和测试集上的性能都是最好的或次优的。它在A组和B组测试集之间的性能差异也最小，表明该模型使用的特征可以很好地概括分布。字节n-gram模型在B组测试集上具有较高的精度和AUC，但该模型在a组和B组性能之间也存在较大差距，表明过拟合
(Raff等人2016)。字节n-gram模型对于输入中的单字节变化也很脆弱，这将导致特征从模型的考虑中有效地
“消失”。当我们认为恶意软件是由能够影响此类更改的对手编写时，这一点很重要，这使得字节
n
语法成为次优方法。我们的MalConv架构没有同样的问题，需要做更多的工作才能解决。使用在PE-Header上训练的模型很好地推广到a组测试数据，实现了比MalConv略高的精度，但在精度和AUC方面显着降低了B组的性能。这显示了一些健壮性，但在指定的相同功能并没有在域之间平等使用。总体而言，MalConv在所有数据和指标上提供了最令人鼓舞的性能平衡。</p>
<p>Dekov正则化的应用显着提高了A组和B组测试集的模型精度。这是一个有点不寻常的属性，因为看来dekov的主要影响是改善决策阈值的校准，而不是模型学到的基本概念。这是Raff，Sylvester和Nicholas
(2017)
为他们的PE头网络指出的一个问题。应用DeCov成功地改善了模型输出概率的校准，将精度提高了4.8点。</p>
<p>使用更大的200万文件语料库，我们还可以看到MalConv模型提高了性能，将a组和B组的精度提高了5.9和1.3点，将B组的AUC提高了2.4点。我们还复制了原始
B 组训练数据使用的字节 n-gram 模型，发现在 A 组测试集上的准确率下降了
4.4 分，AUC 下降了 5.0 分。 B
组的测试成绩也有所下降，但并不显着。这突出了预测的脆性和用于恶意软件检测的字节n-g的过拟合的倾向
(Raff等人2016)。我们的MalConv网络的改进与更多的数据突出了它的优势，它有更大的能力来解决这个问题比以前的领域知识免费的方法。</p>
<h2 id="人工分析">人工分析</h2>
<p>使用我们的架构设计，我们能够对模型学到的内容进行适度的手动分析。我们通过调整
Zhou 等人使用的方法来做到这一点。
(2016)，它为输出中的每个类生成一个类激活图
(CAM)。我们在工作中使用全局最大池化层，而不是最初提出的平均池化。这样做会产生一个自然稀疏的激活图，它有助于可解释性，我们称之为稀疏
CAM。考虑到我们二进制文件的极端序列长度，这是一个关键的设计选择，因为检查所有
200 万字节是不切实际的。 这种稀疏 CAM 设计将返回一个 500
字节区域作为每个卷积滤波器的“重要”区域； 由于我们的模型使用 128
个过滤器，因此每个二进制文件最多标记 128 个区域。</p>
<p>这种方法使我们能够为表示学习网络的良性或恶意的区域生成 CAM
映射。这种对良性或恶意的偏好由生成的激活图的符号决定。使用PE文件库（Carrera
2007），我们可以将大多数二进制文件解析到不同的区域。这些区域对应于二进制格式的不同部分。例如，有一个PE头指定文件的区域。我们期望任何方法都能从该区域学习重要信息，因为它是二进制文件中最结构化和最易于访问的部分。然后，PE头标识二进制文件的哪些部分存储了可执行代码
(.text或代码段) 、全局变量 (.data)
等。通过确定每个稀疏CAM发生在哪个区域，我们可以了解模型正在学习的内容。我们将结果应用于从
A 组测试集中随机选择的 224 个（7 个小批量）二进制文件。
这使我们能够最好地评估网络的广义知识，结果如图 3 所示。</p>
<p>以前在该数据上建立字节n-gram模型的工作发现字节n-gram从PE-Header获得了几乎所有的信息
(Raff等人2016)。基于sparseCAM位置，我们发现MalConv正在使用的信息中只有58-61%
也来自PE标头，这表明正在使用更多的信息类型。.rsrc
部分指示资源目录的使用，其中可以存储文件图标（但也包括可执行代码）等内容。重要的是，我们还看到
.text 和 CODE
部分激活，这表明我们的模型正在使用一些可执行代码作为功能。同样，在 .data
和 .rdata
中找到的应用程序数据表明我们的模型可能正在检测二进制文件之间的常见结构模式。</p>
<p>我们特别注意到，正如我们的网络所了解到的那样，UPX1部分既表示了良性二进制文件，也表示了恶意二进制文件。UPX1部分表示包装的使用，特别是广泛使用的UPX封隔器
(Oberhumer、moln á r和Reiser
1996)。打包会将大部分二进制文件压缩或加密到一个在运行时提取的归档文件中。这使得简单的静态分析变得困难，恶意软件作者中普遍存在打包现象，从而阻碍恶意软件分析。然而，单独打包并不是一个可靠的恶意软件指标，因为许多良性应用程序也被打包（Guo、Ferrie
和 Chiueh
2008）。打包恶意可执行文件的盛行导致许多模型学习“打包”和“恶意”之间的直接（但无益的）等价性。我们的结果表明我们的模型可能避免了这种关联。我们希望可解释模型的进一步进展将帮助我们确认这种行为，并确定哪些微小的细节允许模型改变其倾向。</p>
<h2 id="批量标准化的失败">批量标准化的失败</h2>
<p>我们的结果似乎与许多其他作品中报告的结果相冲突，因为在 MalConv
中添加批量标准化在几个 epoch
后始终无法学习。用批标准化训练的模型充其量将获得 60% 的训练和 50%
的测试准确度。
这种现象发生在所有架构设计变体中。我们对这个结果的惊讶促使我们在
PyTorch、Tensorflow、Chainer 和 Theano
中使用批量标准化来实现这个和其他架构。 Batch-norm
在所有情况下都无法收敛或泛化。</p>
<p>为了诊断这个问题，我们从批量标准化假设数据应该重新拟合到单位正态分布这一事实开始。然后，我们绘制了网络中各层的预激活函数响应以及高斯分布的响应，如图
2
所示。该图显示了在图像或二进制可执行文件上训练的网络中早期层响应的核密度估计。在图像数据上训练的网络显示出近似高斯分布的激活（平滑和单峰），而我们网络的激活分布表现出更大的粗糙度。由于批量归一化假设要归一化的数据是正态分布的，这可能是它在我们的应用程序中无效的原因。
我们建议任何对新问题进行批标准化的应用都会产生类似的可视化，作为诊断收敛问题的方法。</p>
<p>我们假设批处理规范在我们的模型中的无效性是二进制可执行文件训练的产物。大多数当代深度学习研究，包括批量归一化，都是在图像和信号处理领域完成的，自然语言紧随其后。在所有这些领域中，数据的性质相对一致。相比之下，我们的二进制数据呈现了字节值的新的多模态特性。.根据位置的不同，相同的字节值可能具有截然不同的含义，范围从
ASCII
文本、代码、结构。我们的假设是，这种多模态特性会产生多种激活模式，这违反了batchnormalization的主要假设，导致性能下降。</p>
<p>我们使用仅500到10,000字节的二进制随机块训练的模型的测试支持此假设。当在这样的随机子区域上训练时，大多数字节在呈现时将具有单个模态，因此呈现更平滑的单峰激活模式。这是唯一的情况，批处理范数能够达到高于我们的数据60%
的高训练精度，但仍然没有推广到测试数据 (仅获得50%
的随机猜测精度)。从而呈现更平滑的单峰激活模式。这是唯一的情况，批处理范数能够达到高于我们的数据60%
的高训练精度，但仍然没有推广到测试数据 (仅获得50% 的随机猜测精度)。</p>
<h1 id="总结">总结</h1>
<p>在这项工作中，我们描述了神经网络在整个可执行文件的原始字节上的使用。此解决方案避免了更常见的字节n-gram方法的许多问题，例如脆性特征和过度关注PE标头作为重要信息。尽管学习前所未有的序列问题面临挑战，但它在两个测试集中实现了一致的泛化。</p>
<p>在更广泛的机器学习背景下，我们已经确定了许多独特的学习挑战，并讨论了解决极长序列分类的技术。
我们的工作已将神经网络的应用扩展到图像、语音等领域之外的领域，并扩展到具有更复杂的空间相关行为的领域。
在这样做的过程中，我们发现了非常常用的批量标准化的潜在缺陷，并提出了一种检查该技术是否合适的方法（预激活函数响应的正态性测试）。</p>
<p>在未来的工作中，我们希望进一步开发适用于该领域的架构，进一步探索批量归一化问题，并确定哪些类型的现有归一化或权重初始化方案适用于这种多模态响应。
还必须对可以减少该问题的内存密集型性质的方法进行批判性思考，以及哪些类型的架构设计可以让我们更好地捕获二进制中表示的多种信息模式。
对程序进行字节级理解的一般方法将有许多超出恶意软件分类的应用，例如静态性能预测和自动代码生成。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Malware-Detection/">Malware Detection</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">论文翻译</a>
                    
                      <a class="hover-with-bg" href="/tags/%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8B/">恶意代码检测</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022-05/%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E8%AF%86%E5%88%AB%E6%B1%87%E6%8A%A5/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">恶意代码检测汇报</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022-05/Go%E5%9F%BA%E7%A1%80Web%E5%BC%80%E5%8F%914/">
                        <span class="hidden-mobile">Go基础Web开发-数据库操作</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        豫ICP备2022006334号-1
      </a>
    </span>
    
      
        <span>
          <a
            href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=41900102411004"
            rel="nofollow noopener"
            class="beian-police"
            target="_blank"
          >
            
              <span style="visibility: hidden; width: 0">|</span>
              <img src="/images/system/beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"/>
            
            <span>豫公网安备 41900102411004号</span>
          </a>
        </span>
      
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
